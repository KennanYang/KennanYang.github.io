---
title: 机器学习：车辆分割任务和卷积神经网络课堂实践
date: 2022-06-13 09:44:24
categories: 机器学习
tags:
- 机器学习
- python
- 卷积神经网络
---
这是在学习《机器学习基础》课程的**神经网络**这一章时，做的期末大作业，详见《机器学习（周立华）》第五章，记录一下以便回顾。

数据集: kaggle车辆分割数据集
完整代码见github：[车辆分割任务和卷积神经网络课堂实践](https://github.com/KennanYang/Kaggle_car_segmentation)
<!--more-->
## 算法基础
本实验的模型主要参考[FCN语义分割模型](https://blog.csdn.net/qq_36269513/article/details/80420363)，代码部分参考了[手提包分割代码](https://blog.csdn.net/u014453898/article/details/92080859)。
### 1.模型思路
 
![图 1模型结构示意图](https://pic.imgdb.cn/item/62a95ff40947543129ab41ae.png)
如图1所示，模型由两部分组成：上方蓝绿相间的**下采样卷积部分**与下方的**上采样部分**。总体思路是通过卷积过程，将原图一步一步提取出高维全局特征，再使用反卷积操作由高维全局特征还原成原图大小的像素级分类结果。

本项目的下采样卷积部分取用的是 [VGG net网络](https://baijiahao.baidu.com/s?id=1667221544796169037&wfr=spider&for=pc) 卷积部分，其优势是网络结构规整，全网络采用的卷积核尺寸以及池化尺寸均一致, 进行反卷积的尺寸计算较为方便; 且有不同类型的网络结构可以进行横向对比; VGG net通过加深网络深度, 对特征提取的效果也有显著的提升。 

本项目的上采样部分采用反卷积的方式，该方式为上采样的经典操作，通过填充再正向卷积两个步骤，将原来较小尺寸的输入扩大到较大尺寸的输出，并保留了输入时的必要信息。在本项目的实际操作中，并没有将卷积层的输出直接一步还原成原图大小的最终输出，而是一步一步地放大并与所有的池化层输出进行结合，最终还原成原图的大小。
### 2.下采样

下采样部分包含了传统的卷积层与池化层，卷积层即使用卷积核对输入进行卷积运算，运算过程示意如图2所示，卷积核对当前卷积层输入进行从左到右、自上而下的扫描，每一步输出一个结果，如果扫描的是多通道输入，则对每一个通道进行扫描，每一步将多个通道对应的多个结果进行加和即可。
 
![图 2卷积运算](https://pic.imgdb.cn/item/62a95ff40947543129ab4196.png)

池化层的池化运算如图3所示，即对输入进行类似卷积运算中的扫描过程，以最大池化层为例，每一步对窗口中的最大元素进行输出。
 
![图 3池化运算](https://pic.imgdb.cn/item/62a95ff40947543129ab418e.png)
### 3.上采样
本项目采用的反卷积操作进行上采样，Pytorch对反卷积已有了完整可调用的封装函数，而其具体的运算过程分为两步：填充、正向卷积。

![图 4填充过程](https://pic.imgdb.cn/item/62a95ff40947543129ab4187.png)

填充过程如图4所示，填充后输入矩阵中的各行各列元素之间会相隔一层0，对于“same”类型的卷积运算，还会在矩阵外圈填充一层0，这样的填充结果即为图3右边所示。
需要注意的是，输出尺寸是由输入尺寸、正向卷积核大小、填充数决定，如果程序发现当前填充数得到的输出尺寸不满足预定的输出尺寸（即当前输出尺寸偏小），会继续填充，其补填方式是在左侧与上侧继续填充一层0，直至输出尺寸达到预定要求。上述以填充0为例进行说明，而操作者可根据实际情况自定义填充内容，默认填充值为0。

在填充完成后，第二步将进行正向卷积，其卷积运算与下采样部分的卷积运算相同，都是使用卷积核进行扫描、对应位置相乘并相加、多通道输出再相加。输入尺寸经过填充后会被放大一定程度，正向卷积又会减小一定程度，但最后的尺寸会根据填充数、正向卷积核尺寸、步长等变量进行计算，且大于输入尺寸。

考虑到下采样部分的特征提取具有从细节到抽象、从局部到全局的特点，通俗来说可以描述为，网络在卷积部分开始时学习到的是图像某一部分的特征，而前向传播到网络后半程时，网络所掌握到的是对整个图像的总体印象。

不难发现，如果只使用卷积网络最后的输出进行上采样，则保留的信息是全局信息，缺乏细节信息对于总体精度的调整，因此本项目将卷积网络中所有的池化层输出都融入了上采样过程当中，具体做法是：

（1）将卷积网络输出作为当前的上采样对象，将最后一个池化层作为目标池化层
（2）对上采样对象进行反卷积，尺寸扩大一定程度，且通道数也进行扩充，使之与目标池化层尺寸与通道数一致。
（3）将（2）中反卷积后的结果与目标池化层进行对应元素相加。
（4）将（3）操作结束后的输出作为当前的上采样对象，将当前目标池化层的前一个池化层替换当前的目标池化层。跳回（2），循环至所有池化层被融入整个上采样过程。
（5）将最后的结果进行正向卷积，还原成原图片尺寸，此时的输出即为该样本的像素级分类结果。

## 数据处理
### 1.图像缩放
为了达到降低数据维度减少训练模型时间的目的，同时保证缩小后的图片仍能保留原图片的关键信息，因此将图片尺寸缩小到（192，128）。缩小方法采用双线性插值法，即在两个方向分别进行一次线性插值，见下图：
![图 5 双线性插值法](https://pic.imgdb.cn/item/62a95ff40947543129ab41bc.png)
假如我们想得到未知函数 f 在点 P = (x, y) 的值，假设我们已知函数 f 在 $Q_{11}  = (x_1, y_1)、Q_{12} = (x_1, y_2), Q_{21} = (x_2, y_1) 以及 Q_{22} = (x_2, y_2)$ 四个点的值。f就是一个像素点的像素值。首先在 x 方向进行线性插值，得到
![](https://pic.imgdb.cn/item/62a962d90947543129af372e.png)
然后在 y 方向进行线性插值，得到
![](https://pic.imgdb.cn/item/62a962d90947543129af36c6.png)
综合起来就是双线性插值最后的结果：
![](https://pic.imgdb.cn/item/62a962d90947543129af3658.png)
图像双线性插值只会用相邻的4个点,最终还要将源图像和目标图像几何中心的对齐：
![](https://pic.imgdb.cn/item/62a962d90947543129af361d.png)
### 2.归一化
把数据变成(0，1)之间的小数，为了数据处理的方便性和正确性，便于不同单位或量级的指标能够进行比较和加权。归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。

本次实验数据为图片，处理的数值为像素点，由于像素点的值在（0，255）之间，采用区间放缩法，将数据映射到（0，1）之间。即：

$x' = (x - X_{min}) / (X_{max} - X_{min})$

### 3.标准化
标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，转换为标准正态分布，和整体样本分布相关，每个样本点都能对标准化产生影响。
即：$x' = (x - μ)／σ$，
其中μ为均值，σ为标准差。
### 4.独热编码
独热编码即 One-Hot 编码，又称一位有效编码，其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效。对于每一个特征，如果它有m个可能值，那么经过独热编码后，就变成了m个二元特征。并且，这些特征互斥，每次只有一个激活。因此，数据会变成稀疏的。

这样做解决了分类器不好处理属性数据的问题，并且在一定程度上也起到了扩充特征的作用。
### 5.数据集划分
由于提供的数据集中的测试集并无标签信息，因此将训练集按照3：1：1的比例将其划分为训练集、验证集和测试集。

训练集用以训练模型优化参数，验证集用来实时输出总损失值，用以决定合适的迭代次数，避免欠拟合、过拟合以及局部最优。测试集用以计算评价指标，以反映模型效果的好坏。

## 实验效果
### 1.预测结果展示
    
![图 6 测试集原图（左）和预测结果（右）对比展示](https://pic.imgdb.cn/item/62a963fb0947543129b0eadc.png)

这是使用1008个样本的测试集预测之后的结果。其中，左图为原来的车辆图片，分辨率为1918*1280。右图为预测之后形成的灰度图，考虑到性能限制，压缩到分辨率为192*128。

可以看到预测结果基本符合预期。
### 2.MIoU语义分割标准度量
 
![图 7 MIoU语义分割标准度量原理示意图](https://pic.imgdb.cn/item/62a963fb0947543129b0eacd.png)
Mean Intersection over Union（MIoU，均交并比）为语义分割的标准度量。其计算两个集合的交集和并集之比，在语义分割问题中，这两个集合为真实值和预测值。

首先计算单张图片预测结果的交并比，然后把所有测试集中的图片预测结果的交并比取平均值，即可获得MIoU评价指标。

在本次实验中，对比了4种VGG网络模型以及不同迭代次数下的MIoU指标，对比结果如折线图所示。
 
![图 8 对比四种网络结构和不同迭代次数下的MIoU结果](https://pic.imgdb.cn/item/62a963fb0947543129b0eac5.png)

由图中可以看出：
1.这四个网络前期收敛速度是差不多的，随着迭代次数的增加，准确度趋于平稳。
2.性能最好的情况为采用VGG16网络，迭代100次下的网络模型。最优MIoU指数可达到0.9639。

## 参考资料
1.FCN的学习及理解
https://blog.csdn.net/qq_36269513/article/details/80420363

2.卷积神经网络VGG16详解
https://baijiahao.baidu.com/s?id=1667221544796169037&wfr=spider&for=pc

3.MIoU 源码解析——TensorFlow 和 PyTorch 源码解析 
https://zhuanlan.zhihu.com/p/141704816

4.pytorch用FCN语义分割手提包数据集
https://blog.csdn.net/u014453898/article/details/92080859

5.《机器学习》，周志华著
